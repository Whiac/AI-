此文档为AI学习知识树起点
个人认为学习AI应当从LLM出发，*想要使用工具就必须要了解工具的构造、原理；在这里我将会讲解LLM的工作原理、相关名词等等。

/*第一章 LLM概述：我对于AI的看法*/  接受——处理——输出  
（《马大帅》：21世纪现代人的通行证；外语；计算机和驾照；2023年之后：现代人的通行证：终身学习、AI）


##个人对于AI的看法（随时更新）
#2024.2.29；个人关于现今AI的看法
LLM在当今互联网可谓是呼风唤雨，热度极高。无论是OpenAI的sam altman的舆论营销也好，但是事实是：在这繁华的背后，并不是所有人都意识到了LLM将会对未来产生多么大的转变。
在当前以我个人的观点来看：我十分赞同许多科技圈大佬的观点，这次的LLM不亚于第一、二次工业革命，当你越深入了解这个行业就会发现他的恐怖之处；或许在现在很多人还在嗤之以鼻，认为AI永远代替不了人类，保持AI无用论的观点。
##但是在我的视角来看AI的未来趋势有以下两点，会轻易的击碎许多人的观点：
1.AI及其相关行业发展速度超迅速，在仅仅一年多的时间发展速度呈现指数级增长，会在很多行业形成范式转移。
2.AI不会代替人，但是人会代替人；能够使用AI的人会远远的超过不使用AI的人。差距甚至会超过不使用互联网，就像那个互联网笑话一样：你的村里才通网？
到时候掌握AI的人和不使用AI的人会比人和动物之前的差距还要大！！！


##LLM概述
LLM（large language model）翻译为大语言模型，也可以直接当做大家认识中的AI，例如GPT、Gemini、LLaMa等你可能听过的大模型
为什么叫做大语言模型？

#首先我们来聊一聊“语言”的含义
LLM他的工作原理，简单来说就是猜词游戏，（以下内容以知名度最高的GPT所使用的模型原理进行说明）
例如“终身成长”这个词语我擦掉了“成长”这两字就变成了“终身XX”，这时LLM就会开始猜测我后面的XX是什么？我想填入什么？
如果他是一只受过训练的鹦鹉，就有可能回答出“学习”、“成长”等比较靠近语义的词；但如果是一直完全没经过训练的鹦鹉，他有可能会回复我各种词语“吃饭”、“走路”、“去游泳”，不仅仅是词语的数量或者含义都会有很大的差异。

那么为什么AI能够被训练成——“听话的鹦鹉”呢？
这里就和“大模型”有关了
通俗来讲，大模型的含义就单单指他的模型规模巨大，目前GPT4的训练数据已经超过1.8万亿。这也是当前“通用”大模型的发展方向，让大模型吸收各行各业的大量知识（有一定“量变引起质变的意思”）
那么现在我们可以尝试去理解LLM的含义了，通过海量的知识数据来进行训练“鹦鹉”，并通过“注意力”机制（transformer架构由Attention is all you need产出，我们后面会介绍一些其他的NLP机制）
（论文地址：https://arxiv.org/abs/1706.03762  论文精读：https://zhuanlan.zhihu.com/p/46990010）
具体的工作原理可以看这里
（https://www.bilibili.com/video/BV12N411x7FL/?spm_id_from=333.337.search-card.all.click&vd_source=1599517ebe5de45944d55ef218ad0eb5）

在上述的内容中我相信你已经了解了LLM大致是什么，工作原理是什么？
接下来的章节我将会深入讲解LLM最重要的NLP
